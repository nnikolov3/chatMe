{
    "file_path": "src\\files_to_process\\test_file.pdf",
    "file_hash": "e623f62927b0b4af4529ae8da975ad8c8bbcb1981c3642692ac81f088da571ca",
    "processed_date": "2025-01-01T14:05:11.029659",
    "content": {
        "pages": [
            {
                "page_0": {
                    "ocr_text": "function takes up most of the GPU resources (e.g., shared\nmemory, registers, etc.). In that case, a different CUDA func-\ntion will only be scheduled after all the thread blocks in the\nprevious CUDA function finished execution [3]. Therefore,\non GPUs with few SMs, this is less likely to be an issue as\nthe GPU\u2019s resources are already saturated due to the large\ncomputational demand of DNN inference.\n\nBias Extraction in INT8 Implementations We demon-\nstrated the extraction of biases from convolutional layers for\nFP16 implementations but not INT8 implementations. These\nimplementations only use INT8 for the weights but not for\nthe bias. The bias in these implementations has FP32 data\ntype, which is beyond our computing capabilities to extract.\n\n6.4 Mitigation\n\nTraditional ways to contain electromagnetic emanation, such\nas proper shielding or introducing noise to decrease the Signal-\nto-Noise ratio, could alleviate the problem [42]. Specifically\nagainst parameter extraction, one of the possible countermea-\nsures, which is also mentioned in the CSI-NN paper [13], is\nshuffling [61] the order of multiplications in the layers, which\ncan make it significantly harder for an adversary to recover\nthe weights. Additionally, masking [19, 48] can also decou-\nple the side-channel measurements and the processed data.\nHowever, this comes at the price of execution speed, which\nmight not be desired in real-time systems. Specifically for\nconvolution, the registers containing the results of the partial\nsums can be initialized with the bias of the kernel instead of\ninitializing them with zeros. This would prompt an adversary\nto mount a CEMA attack where the correct b+ w, pair has\nto be recovered first. The complexity of this attack would be\n32 bits due to 16 bits of complexity for the weight and bias\nseparately in the FP16 case. However, in the INT8 case, the\nbias is a single-precision float, so it cannot be used to initialize\nthe accumulator registers.\n\nClock Side Parameter\nAuthor Platform (MHz) channel datatype\nBatina, et al. [13] MCU 20, 84 EM FP32\nDubet, et al. [21] FPGA 24 Power Binary\nYoshida, et al. [64] FPGA 25 Power INT8\nRegazzoni, et al. [53] | FPGA N/AS EM Binary\nYli-Mayry, et al. [63] | FPGA N/A8 EM Binary\nLi, et al. [37] FPGA 25 Power INT8\nJoud, et al. [31] MCU 100 EM FP32\nGongye et al. [25] FPGA 320 EM INT8\nBarraCUDA GPU 625,920 EM INT8, FP16\n\nTable 3: Comparison with related work.\n\n6.5 Related Work\n\nTo the best of our knowledge, no previous work has been\nable to extract the parameters of neural networks on GPU us-\n\ning physical side-channel. Previous works have demonstrated\nparameter extraction on microcontrollers and FPGAs using\npower or EM side channel, as shown in Table 3. In addition,\nthese attacks were performed on neural networks with binary\nparameters [21, 53, 63], 8-bit parameters [13, 25, 37, 64] or\n32-bit parameters [13, 31]. Our work demonstrates parame-\nter extraction of 8- and 16-bit parameters. Furthermore, our\nwork presents a CEMA attack on weights where the number\nof cores and the clock frequency at these cores operate are\nsignificantly larger than in related works. The large number\nof cores, with almost 1GHz clock frequency, presents a chal-\nlenge in both the measurement and attack stages. Given that\nGPUs are the backbone of AI, it is of utmost importance to\nassess the resilience of GPU accelerated workloads against\nweight extraction attacks, a task our research addresses.\n\n7 Conclusions\n\nIn this work, we analyzed the GPUs of Nvidia Jetson Nano\nand Nvidia Jetson Orin Nano, commonly chosen platforms\nfor real-world neural network implementations, for resilience\nagainst side-channel attacks that aim to extract the weights\nof the target NN. First, we find multiple vulnerable points\nwhere the GPUs leak information about the parameters of the\ntarget DNN. Subsequently, we demonstrate the extraction of\nweights and biases of convolutional and dense layers. Overall,\nthe neural network implementations of Nvidia\u2019s TensorRT\nframework are vulnerable to parameter extraction using EM\nside-channel attack despite the networks running in a highly\nparallel and noisy environment. Protecting their implementa-\ntions in security or privacy-sensitive applications remains an\nopen problem.\n\nAcknowledgments\n\nThis research was supported by: an ARC Discovery Project\nnumber DP210102670; the Deutsche Forschungsgemein-\nschaft (DFG, German Research Foundation) under Germany\u2019s\nExcellence Strategy - EXC 2092 CASA - 390781972; Ai-\nSecTools (VJO2010010); PROACT project of Dutch Research\nAgenda (NWA.1215.18.014) and Netherlands Organisation\nfor Scientific Research (NWO); TTW PREDATOR project\n19782 (NWO).\n\nReferences\n\n[1] https://www.langer-emv.de/en/product /mfa-\nactive-1mhz-up-to-6-ghz/32/mfa-r-0-2-\n75-near-field-micro-probe-1-mhz-up-to-1-\n\nghz/854. Accessed: 2022-01-25.\n\n8The clock frequency is not disclosed in these attacks, but it is at most\n800MHz as both attack XILINX ZYNQ chip [12].\n",
                    "first_vision_analysis": "**Title:**\nGPU vs AI Hardware for Machine Learning\n\n---\n\n**Body Text:**\n\nfunction takes up most of the GPU resources (e.g., shared memory, registers, etc.). In that case, a different CUDA function will only be scheduled after all the thread blocks in the previous CUDA function finished execution [3]. Therefore, on GPUs with few SMs, this is likely to be an issue as the GPU's resources are already saturated due to the large computational demand of DNN inference.\n\n**Subsection:**\nBias Extraction in INT8 vs. FP16 Implementation\n\nWe demonstrated the extraction of biases from convolutional layers for FP16 implementations but not INTF implementationes. These layer uses only INTF for the weights but not for the activation bias. The use of these implementations has FPS32 data type, which is beyond our computing capabilities to extract.\n\n---\n\n**Section:**\n7. Conclusions\n\nIn this work, we analyzed the GPUs of Nvidia Jetson Nano and Nvidia Jetson Orion NANO, commonly chosen platforms for real-world neural network implementationes, for resilience against side-channel attacks that aim to extract the weights from cores. Additionally, masking [19, 48] can also decouc... However, this comes at the price of execution speed.\n\n---\n\n**Section:**\n6.4 Mitigation\n\nTraditional ways to contain electromagnetic radiation, such as proper shielding or introducing noise-to-Noise ratio, could alleviate the problem in terms of parameter extraction, one of the possible countermeasures...\n\n---\n\n**Table 3: Comparison with related work**\n\n| Clock | Side   | Parameter       |\n|-------|--------|-----------------|\n| MCU   | FPGAs | (MHz)          |\n| EM    | FP24  | ...             |\n| Power | INT8  |                 |\n\n---\n\n**References:**\n1. [Battina, et al., at] (2013)\n2. [Dubet, et al., at] (2021)\n3. [Yoshida, et al., at] (2064)\n\n[Table 5: Related Work]\n\nTo the best of our knowledge, no previous work has disclosed in these attacks; however it is most able to extract the parameters on neural networks on GPU us... \n\n---\n\n**Page Number:** \n14",
                    "second_vision_analysis": [
                        "function takes up most of the GPU resources",
                        "shared",
                        "physical side-channel. Previous works have demonstrated",
                        "memory, registers, etc) In that case, a different CUDA func-",
                        "parameter extraction on microcontrollers and FPGAs",
                        "tion will only be scheduled after all the thread blocks in the",
                        "power or EM side channel, as shown in Table 3. In addition,",
                        "previous CUDA function finished execution [3]. Therefore,",
                        "these attacks were",
                        "performed on neural networks with binary",
                        "on GPUs with few SMs, this is less likely to be an issue as",
                        "parameters [21, 53, 63], &-bit parameters [13, 25, 37, 64] or",
                        "the GPU' s resources",
                        "are",
                        "already saturated due to the large",
                        "32-bit parameters [13, 31]. Our work demonstrates parame-",
                        "computational demand of DNN inference.",
                        "ter extraction of &- and 16-bit parameters. Furthermore, our",
                        "Bias Extraction in INT8 Implementations",
                        "We demon-",
                        "work",
                        "presents",
                        "a",
                        "CEMA attack on weights where the number",
                        "strated the extraction of biases from convolutional layers for",
                        "of cores and the clock frequency at these cores operate are",
                        "FP16 implementations but not INT8 implementations. These",
                        "significantly larger than in related works. The large number",
                        "implementations only use INT8 for the weights but not for",
                        "of cores, with almost IGHz clock frequency, presents a chal-",
                        "the bias. The bias in these implementations has FP32 data",
                        "in both the measurement and attack stages. Given that",
                        "type, which is beyond our computing capabilities to extract",
                        "GPUs are the backbone of AI, it is of utmost importance to",
                        "assess the resilience of GPU accelerated workloads",
                        "against",
                        "6.4",
                        "Mitigation",
                        "weight extraction attacks, a task our research addresses.",
                        "Traditional ways to contain electromagnetic emanation, such",
                        "as proper",
                        "shielding or introducing noise to decrease the Signal-",
                        "7",
                        "Conclusions",
                        "to-Noise ratio, could alleviate the problem [42]. Specifically",
                        "against parameter extraction, one of the possible countermea-",
                        "In this work,",
                        "we",
                        "analyzed the GPUs of Nvidia Jetson Nano",
                        "sures, which is also mentioned in the CSI-NN paper [13], is",
                        "and Nvidia Jetson Orin Nano, commonly chosen platforms",
                        "shuffling [61] the order of multiplications in the layers, which",
                        "for real-world neural network implementations, for resilience",
                        "can make it significantly harder for an adversary to recover",
                        "side-channel attacks that aim to extract the weights",
                        "the weights. Additionally, masking [19, 48] can also decou-",
                        "of the target NN. First,",
                        "we find multiple vulnerable points",
                        "ple the side-channel measurements and the processed data:",
                        "where the GPUs leak information about the parameters of the",
                        "However; this comes at the price of execution speed, which",
                        "target DNN. Subsequently, we demonstrate the extraction of",
                        "might not be desired in real-time systems. Specifically for",
                        "weights and biases of convolutional and dense layers Overall",
                        "convolution, the registers containing the results of the partial",
                        "the neural network implementations of Nvidia's TensorRT",
                        "sums can be initialized with the bias of the kernel instead of",
                        "framework are vulnerable to parameter extraction",
                        "EM",
                        "initializing them with zeros. This would prompt an adversary",
                        "side-channel attack despite the networks running in a highly",
                        "to mount a CEMA attack where the correct b+ W1",
                        "has",
                        "parallel and",
                        "environment: Protecting their implementa-",
                        "to be recovered first: The complexity of this attack would be",
                        "tions in security O privacy-sensitive applications remains an",
                        "32 bits due to 16 bits of complexity for the weight and bias",
                        "open problem.",
                        "separately in the FP16 case. However; in the INT8 case, the",
                        "bias is a single-precision float, so it cannot be used to initialize",
                        "A",
                        "cknowledgments",
                        "the accumulator registers.",
                        "This research was supported by: an ARC Discovery Project",
                        "Clock",
                        "Side",
                        "Parameter",
                        "number DP210102670; the Deutsche Forschungsgemein-",
                        "Author",
                        "Platform",
                        "(MHz)",
                        "channel",
                        "datatype",
                        "schaft (DFG, German Research Foundation) under Germany' $",
                        "Batina, et al. [13]",
                        "MCU",
                        "20, 84",
                        "EM",
                        "FP32",
                        "Excellence Strategy",
                        "EXC 2092 CASA",
                        "390781972; Ai-",
                        "Dubet; et al. [21]",
                        "FPGA",
                        "24",
                        "Power",
                        "Binary",
                        "Yoshida, et al. [64]",
                        "FPGA",
                        "25",
                        "Power",
                        "INT8",
                        "SecTools (VJ02010010); PROACT project of Dutch Research",
                        "Regazzoni, et al. [53]",
                        "FPGA",
                        "NIA8",
                        "EM",
                        "Binary",
                        "Agenda (NWA.1215.18.014) and Netherlands Organisation",
                        "Yli-Mayry, et al. [63]",
                        "FPGA",
                        "NIA8",
                        "EM",
                        "Binary",
                        "for Scientific Research (NWO); TTW PREDATOR project",
                        "Li; et al. [37]",
                        "FPGA",
                        "25",
                        "Power",
                        "INT8",
                        "19782 (NWO):",
                        "Joud, et al. [31]",
                        "MCU",
                        "100",
                        "EM",
                        "FP32",
                        "Gongye et al. [25]",
                        "FPGA",
                        "320",
                        "EM",
                        "INT8",
                        "BarraCUDA",
                        "GPU",
                        "625, 920",
                        "EM",
                        "INT8, FP16",
                        "References",
                        "Table 3: Comparison with related work.",
                        "[1] https :",
                        "langer-emv. de/en/product /mfa-",
                        "active-lmhz-up-to-6-ghz/32/mfa-r-0-2 -",
                        "75-near-field-micro-probe-l-mhz-up-to-1-",
                        "6.5",
                        "Related Work",
                        "ghz / 854. Accessed: 2022-01-25.",
                        "To the best of our knowledge, no previous work has been",
                        "clock frequency is not disclosed in these attacks, but it is at most",
                        "able to extract the parameters of neural networks on GPU us-",
                        "8OOMHz as both attack XILINX ZYNQ chip [12].",
                        "14",
                        "ing",
                        "(e.g ,",
                        "using",
                        "lenge",
                        "against",
                        "using",
                        "noisy",
                        "pair",
                        "[www",
                        "8The"
                    ]
                }
            }
        ],
        "total_pages": 1
    }
}